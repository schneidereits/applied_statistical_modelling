---
title: "Exercise week 12"
author: "Shawn Schneidereit"
date: "`r Sys.Date()`"
output: html_document

---


```{r, include= FALSE}
library(tidyverse)
library(dplyr)
library(readr)
library(viridis)
library(ggeffects)
library(FactoMineR)
library(rethinking)
library(brms)
library(patchwork)

```

#13E2.
Rewrite the following model as a multilevel model.
yi ∼ Binomial(1, pi)
logit(pi) = αgroup[i] + βxi
αgroup ∼ Normal(0, 1.5) 
β ∼ Normal(0, 0.5)


```{}
  brm(data = d, 
      family = binomial,
      yi | trials(density) ~ 1 + (1 | group) + xi,
     prior = c(prior(normal(0, 1.5), class = Intercept),  #bar alpha
               prior(normal(0,0.5), class = b)),          # beta

```

#13E3.
Rewrite the following model as a multilevel model.
yi ∼ Normal(μi, σ)
μi = αgroup[i] + βxi
αgroup ∼ Normal(0, 5) 
β ∼ Normal(0, 1)
σ ∼ Exponential(1)

```{}
  brm(data = d, 
      family = gaussian,
      yi | trials(density) ~ 1 + (1 | group)+ xi,
     prior = c(prior(normal(0, 1.5), class = Intercept),  #bar alpha
               prior(normal(0,1), class = b),              # beta
               prior(exponenial(1), class = sd, group=xi)), # sigma

```

#13M1. 
Revisit the Reed frog survival data, data(reedfrogs), and add the predation and size treatment variables to the varying intercepts model. Consider models with either main effect alone, both main effects, as well as a model including both and their interaction. Instead of focusing on inferences about these two predictor variables, focus on the inferred variation across tanks. Explain why it changes as it does across models.

```{r}
data(reedfrogs, package = "rethinking")
data <- reedfrogs
data %>% glimpse()

data <- data %>%
  mutate(tank = 1:nrow(data))
```

```{r, message=FALSE, warning=FALSE, results=FALSE}
m_size <- brm(data = data, 
      family = binomial,
      surv | trials(density) ~ 1 + size + (1 | tank),
      prior = c(prior(normal(0, 1.5), class = Intercept),  
      prior(normal(0, 0.5), class = b)),
      prior(exponential(1), class = sd),         
      iter = 5000, warmup = 1000, chains = 4, cores = 4,
      sample_prior = "yes",
      seed = 25)
```

```{r}
pp_check(m_size)
plot(m_size)
summary(m_size)
p_size <- mcmc_plot(m_size)
```


```{r, message=FALSE, warning=FALSE, results=FALSE}
m_pred <- brm(data = data, 
      family = binomial,
      surv | trials(density) ~ 1 + pred + (1 | tank),
      prior = c(prior(normal(0, 1.5), class = Intercept),  
      prior(normal(0, 0.5), class = b)),
      prior(exponential(1), class = sd),         
      iter = 5000, warmup = 1000, chains = 4, cores = 4,
      sample_prior = "yes",
      seed = 25)
```


```{r}
pp_check(m_pred)
plot(m_pred)
summary(m_pred)
p_pred <- mcmc_plot(m_pred)
```


```{r, message=FALSE, warning=FALSE, results=FALSE}
m_size_pred <-  brm(data = data, 
      family = binomial,
      surv | trials(density) ~ 1 + size + pred + (1 | tank),
      prior = c(prior(normal(0, 1.5), class = Intercept),  
      prior(normal(0, 0.5), class = b),
      prior(exponential(1), class = sd)),         
      iter = 5000, warmup = 1000, chains = 4, cores = 4,
      sample_prior = "yes",
      seed = 25)


```
      
```{r}
pp_check(m_size_pred)
plot(m_size_pred)
summary(m_size_pred)
p_size_pred <- mcmc_plot(m_size_pred)
```

      
```{r, message=FALSE, warning=FALSE, results=FALSE}
m_inter <- brm(data = data, 
      family = binomial,
      surv | trials(density) ~ 1 + size + pred + size:pred + (1 | tank),# addition + interaction 
      prior = c(prior(normal(0, 1.5), class = Intercept),  
      prior(normal(0, 0.5), class = b),
      prior(exponential(1), class = sd)),         
      iter = 5000, warmup = 1000, chains = 4, cores = 4,
      sample_prior = "yes",
      seed = 25)
```


```{r}
pp_check(m_inter)
plot(m_inter)
summary(m_inter)
p_inter <- mcmc_plot(m_inter)
```


```{r}
(p_size | p_pred)
(p_size_pred | p_inter)
```

The most obvious way in which variation between tanks changes between the models is that the size only has a larger estimate with far greater estimated error. In comparison the three following models that all include predation all have smaller estimates and errors. The reason for this change between models is that predation is as a variable in the model, it accounts for the additional observed variation that was attibuted to between tank differences in the size only model.

#13M2. 
Compare the models you fit just above, using WAIC. Can you reconcile the differences in WAIC with the posterior distributions of the models?

```{r}
# Adding criteria to the model and comparing it with the models of 12H1
waic_size <- add_criterion(m_size, criterion = "waic") 
waic_pred <- add_criterion(m_pred, criterion = "waic")
waic_size_pred <- add_criterion(m_size_pred, criterion = "waic") 
waic_inter <- add_criterion(m_inter, criterion = "waic") 

comparison_waic <- loo_compare(waic_size, waic_pred, waic_size_pred, waic_inter, criterion = "waic")
print(comparison_waic, simplify = FALSE)

loo_size <- add_criterion(m_size, criterion = "loo") 
loo_pred <- add_criterion(m_pred, criterion = "loo")
loo_size_pred <- add_criterion(m_size_pred, criterion = "loo") 
loo_inter <- add_criterion(m_inter, criterion = "loo") 

comparison_loo <- loo_compare(loo_size, loo_pred, loo_size_pred, loo_inter, criterion = "loo")
print(comparison_loo, simplify = FALSE)
```

Yes, the differences in WAIC (and loo) can be reconciled with the in posterior distributions, as based on the compairison tables it can be seen that all three models that contain predation as a variable have relatively compairable elpd_loo values, where as the size model has a outlying low score.  
