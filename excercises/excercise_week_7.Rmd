---
title: "Exercise week 7"
author: "Shawn Schneidereit"
date: "`r Sys.Date()`"
output: html_document
---


```{r, include= FALSE}
library(tidyverse)
library(dplyr)
library(readr)
library(viridis)
library(ggeffects)
library(FactoMineR)
library(rethinking)
library(brms)
```


### 8H1 Return to the data(tulips) example in the chapter. Now include the bed variable as a pre- dictor in the interaction model. Donâ€™t interact bed with the other predictors; just include it as a main effect. Note that bed is categorical. So to use it properly, you will need to either construct dummy variables or rather an index variable, as explained in Chapter 5.

```{r}
data(tulips, package = "rethinking")
d <- tulips
rm(tulips)

head(d)
```


```{r, message=FALSE, warning=FALSE, results=FALSE}
d <-
  d %>% 
  mutate(blooms_std = blooms / max(blooms),
         water_cent = water - mean(water),
         shade_cent = shade - mean(shade))

b8 <-
  brm(data = d, 
      family = gaussian,
      blooms_std ~ 1 + water_cent + shade_cent + water_cent:shade_cent,
      prior = c(prior(normal(0.5, 0.25), class = Intercept),
                prior(normal(0, 0.25), class = b, coef = water_cent),
                prior(normal(0, 0.25), class = b, coef = shade_cent),
                prior(exponential(1), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 42)

b8.1 <-
  brm(
    data = d,
    family = gaussian,
    blooms_std ~ 0 + bed + water_cent + shade_cent + water_cent:shade_cent,
    prior = c(
      #prior(normal(0.5, 0.25), class = Intercept),
      prior(normal(0, 0.25), class = b, coef = water_cent),
      prior(normal(0, 0.25), class = b, coef = shade_cent),
      prior(normal(0, 0.25), class = b, coef = "water_cent:shade_cent"),
      prior(exponential(1), class = sigma)
    ),
    iter = 2000,
    warmup = 1000,
    chains = 4,
    cores = 4,
    seed = 42
  )

```

```{r}
plot(b8)
summary(b8)

plot(b8.1)
summary(b8.1)
```



### 8H2 Use WAIC to compare the model from 8H1 to a model that omits bed. What do you infer from this comparison? Can you reconcile the WAIC results with the posterior distribution of the bed coefficients?

```{r}
b8 <- add_criterion(b8, criterion = "waic") 
b8.1 <- add_criterion(b8.1, criterion = "waic") 

b_waic <- loo_compare(b8, b8.1, criterion = "waic")

print(b_waic, simplify = F)
```

```{r}
b_waic[, 7:8] %>% 
  data.frame() %>% 
  rownames_to_column("model_name") %>% 
  mutate(model_name = fct_reorder(model_name, waic, .desc = T)) %>% 
  
  ggplot(aes(x = waic, y = model_name, 
             xmin = waic - se_waic, 
             xmax = waic + se_waic)) +
  geom_pointrange() +
  labs(title = "My custom WAIC plot",
       x = NULL, y = NULL) +
  theme(axis.ticks.y = element_blank())

```


Can you reconcile the WAIC results with the posterior distribution of the bed coefficients?

From the comparison of the models WAIC we can infer that adding bed to the model provides more valuable information content, than predictive ability that is lossed through overfitting. When comparing the WAICs we can also see that overall the difference between two models is not huge though and there still considerable uncertainty. 

```{r}
psamp <- posterior_samples(b8)[,1:3] %>% 
  pivot_longer(cols = everything())
ggplot(psamp) +
  geom_density(mapping = aes(x = value, group = name, col = name))


psamp <- posterior_samples(b8.1)[,1:3] %>% 
  pivot_longer(cols = everything())
ggplot(psamp) +
  geom_density(mapping = aes(x = value, group = name, col = name))
```


Yes the WAIC results can be reconciled with the posterior distributions, as there is greater overlapp and thus uncertainly  