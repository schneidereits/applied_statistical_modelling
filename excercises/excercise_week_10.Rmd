---
title: "Exercise week 10"
author: "Shawn Schneidereit"
date: "`r Sys.Date()`"
output: html_document

---


```{r, include= FALSE}
library(tidyverse)
library(dplyr)
library(readr)
library(viridis)
library(ggeffects)
library(FactoMineR)
library(rethinking)
library(brms)

```


The data contained in library(MASS);data(eagles) are records of salmon pirating at- tempts by Bald Eagles in Washington State. See ?eagles for details. While one eagle feeds, some- times another will swoop in and try to steal the salmon from it. Call the feeding eagle the “victim” and the thief the “pirate.” Use the available data to build a binomial GLM of successful pirating attempts.

```{r}
library(MASS)
data(eagles, package = "MASS")
data <- eagles
?eagles

# Creating dummy variables
data$pirate_L <- ifelse(data$P == "L", 1, 0)
data$victim_L <- ifelse(data$V == "L", 1, 0)
data$pirate_A <- ifelse(data$A == "A", 1, 0)
str(data)

```


### Q11H2a

Fit the model above to the eagles data, using brms. Is the approximation okay?

```{r, message=FALSE, warning=FALSE, results=FALSE}
b11.h2 <- 
  brm(data = data, 
      family = binomial,
      y | trials(n) ~ 1 + pirate_L + victim_L + pirate_A,
      prior = c(prior(normal(0, 1.5), class = Intercept),
                prior(normal(0, 0.5), class = b)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 11)
```
```{r}
plot(b11.h2)
summary(b11.h2)
mcmc_plot(b11.h2, pars = "^b_")

```

The approximation does look ok. Our chains look like fuzzy caterpillar, meaning that they explore the parameter space well, and Rhat values are all = to one, indicating model convergence.  


### Q11H2b
Then plot the posterior predictions. Compute and display both (1) the predicted probability of success and its 89% interval for each row (i) in the data, as well as (2) the predicted success count and its 89% interval. What different information does each type of posterior prediction provide?

```{r}

# determine the range of `a` values we'd like to feed into `fitted()`
nd <- 
  data %>% 
  distinct(y, n, pirate_L, victim_L, pirate_A)

# predictions of the responses
predict(b11.h2)
# predictions of the regression line
fitted(b11.h2)


 (post_predict <- fitted(b11.h2,
         newdata = nd) %>% 
  data.frame() %>% 
  bind_cols(nd) %>% 
     mutate(row = row_number(),
            predicted_prob = (Estimate / n)))

   #  pivot_longer(pirate_L:pirate_A) %>% 
     #rename(variable = name) %>% 
  #mutate(condition = factor(condition)) %>% 
  
  ggplot(data = post_predict, aes(x = row, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = .5) +
  geom_line(aes(group = row),
            size = 1/4) +
  geom_pointrange(aes(color = row),
                  fatten = 2.5, show.legend = F) + 
  labs(subtitle = "posterior predictions")


```

_Similarly to as what Christen posted in her moodel post, I am unsure how to calculate the 89% CI intervals for aggregated proportion, without running a new model?_

What different information does each type of posterior prediction provide

Conceptually though the posterior prediction from the count column provides a relative assessment of success, were as the proportion column is in absolute terms




### Q11H2c
Now try to improve the model. Consider an interaction between the pirate’s size and age (immature or adult). Compare this model to the previous one, using WAIC. Interpret.

### This question is wrong, as there is only one age variable in the dataset. Instead I used the age of the pirate in interaction with priate *and* victum body size to get a more comprehensive compairison. 

```{r, message=FALSE, warning=FALSE, results=FALSE}

b11.h2c.p <- 
  brm(data = data, 
      family = binomial,
      y | trials(n) ~ 1 + pirate_L + victim_L + pirate_A + pirate_L:pirate_A,
      prior = c(prior(normal(0, 1.5), class = Intercept),
                prior(normal(0, 0.5), class = b)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 11)


b11.h2c.v <- 
  brm(data = data, 
      family = binomial,
      y | trials(n) ~ 1 + pirate_L + victim_L + pirate_A + pirate_L:victim_L,
      prior = c(prior(normal(0, 1.5), class = Intercept),
                prior(normal(0, 0.5), class = b)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 11)

```

```{r}
plot(b11.h2c.p)
summary(b11.h2c.p)
mcmc_plot(b11.h2c.p, pars = "^b_")

plot(b11.h2c.v)
summary(b11.h2c.v)
mcmc_plot(b11.h2c.v, pars = "^b_")

```

```{r}
b11.h2 <- add_criterion(b11.h2, criterion = "waic") 
b11.h2c.p <- add_criterion(b11.h2c.p, criterion = "waic") 
b11.h2c.v <- add_criterion(b11.h2c.v, criterion = "waic") 

b_waic <- loo_compare(b11.h2, b11.h2c.p, b11.h2c.v, criterion = "waic")

print(b_waic, simplify = F)
```
I received warning messages that p_waic exceed the recommended threshold, and thus attempted the same using loo

```{r}
b11.h2 <- add_criterion(b11.h2, criterion = "loo") 
b11.h2c.p <- add_criterion(b11.h2c.p, criterion = "loo") 
b11.h2c.v <- add_criterion(b11.h2c.v, criterion = "loo") 

b_loo <- loo_compare(b11.h2, b11.h2c.p, b11.h2c.v, criterion = "loo")

print(b_loo, simplify = F)
```

```{r}
b_loo[, 7:8] %>% 
  data.frame() %>% 
  rownames_to_column("model_name") %>% 
  
  ggplot(aes(x = looic, y = model_name, 
             xmin = looic - se_looic, 
             xmax = looic + se_looic)) +
  geom_pointrange() +
  labs(title = "loo plot",
       x = NULL, y = NULL) +
  theme(axis.ticks.y = element_blank())
```

Overall the model including the interaction between victim size and pirate age performed best, according to the leave one out information criterion comparison. Including the victim size and pirate age also reduced the elpd SE. Notable is the modeling with the inclusion of the interaction between pirate size and age reduced slightly reduced model performance, when compared to the original. 